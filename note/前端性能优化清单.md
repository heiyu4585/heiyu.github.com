[TOC]

### 渐进增强（progressive enhancement）
在构建前端结构的时候，应始终将渐进增强作为你的指导原则。首先设计并且构建核心体验，随后再完善那些为高性能浏览器设计的高级特性的相关体验，
创建弹性体验。如果你的网页可以在使用低速网络、老旧显示器的很慢的电脑上运行飞快，那么在光纤高配电脑上它只会运行的更快。


#### 直接确定优化顺序
首先应该弄清楚你想解决的问题是什么。检查一遍你所有的文件（JavaScript，图片，字体，第三方script文件以及页面中重要的模块，例如轮播，复杂信息图标和多媒体内容），并将他们分类。
列一个表格。明确浏览器上应该有的基础核心内容，哪些部分属于为高性能浏览器设计的升级体验，哪些是附加内容（那些不必要或者可以被延时加载的部分，例如字体，不必要的样式，轮播组件，播放器，社交网站入口，很大的图片）。更详细的细节请参考文章”Improving Smashing Magazine’s Performance‘’。

#### 使用符合标准的技术
使用符合标准的技术向过时的浏览器提供核心体验，向老式浏览器提供增强体验, 同时对所加载的内容要有严格的把控。即首要加载核心体验部分，将增强部分放在DomContentLoaded，把额外内容发在load事件中。

以前我们可以通过浏览器的版本推断出设备的性能，但现在我们已经无法推测了。因为现在市场上很多廉价的安卓手机都不考虑内存限制和CPU性能，直接使用高版本的Chrome浏览器。一定要注意，在我们没有其他选择的时候，我们选择的技术同时可能成为我们的限制。

#### 考虑微优化和渐进启动
在一些应用中，可以在渲染页面前先初始化应用。最好先显示框架，而不是一个进度条或指示器。使用可以加速初始渲染时间的模块或技术（例如tree-shaking和code-splitting），因为大部分性能问题来自于应用引导程序的初始分析时间。还可以在服务器上提前编译，从而减轻部分客户端的渲染过程，从而快速输出结果。最后，考虑使用Optimize.js来加快初始加载速度，它的原理是包装优先级高的调用函数（虽然现在已经没什么必要了）。

image
渐进启动指的是使用服务器端渲染，从而快速得到首次有效渲染，这个渲染过程也包括小部分的JavaScript文件，目的是使交互时间尽可能的接近首次有效渲染时间。

到底采用客户端渲染还是服务器端渲染？不论哪种做法，我们的目标都是建立渐进启动：使用服务器端渲染可以得到很短的首次有效渲染时间，这个渲染过程也包括小部分的JavaScript文件，目的是使交互时间尽可能的接近首次有效渲染时间。接下来，尽可能的增加一些应用的非必要功能。不幸的是，正如Paul Lewis所说，框架基本上对开发者是没有优先级的概念的，因此渐进启动在很多库和框架上是很难实施的。如果你有时间的话，还是考虑使用策略去优化你的性能吧。

#### HTTP的缓存头使用的合理吗？
仔细检查一下例如expires，cache-control，max-age以及其他HTTP缓存头是否被正确的使用。一般来说，资源不论在短时间（如果它会被频繁改动）还是不确定的时间内（如果它是静态的）都是可缓存的——你大可在需要的时候在URL中成改版本。

如果可能，使用为指纹静态资源设计的Cache-control:immutable，从而避免二次验证（2016年12月，只有FireFox在https://处理中支持）。你可以使用，Heroku的primer on HTTP caching headers，Jake Archibald的 ”Caching Best Practices”，还有IIya Grigorik的HTTP caching primer作为指导。

#### 减少使用第三方库，加载JavaScript异步操作
当用户请求页面时，浏览器会抓取HTML同时生成DOM，然后抓取CSS并建立CSS对象模型，最后通过匹配DOM和CSS对象生成渲染树。在需要处理的JavaScript文件被解决之前，浏览器不会开始对页面进行渲染。作为开发者，我们要明确的告诉浏览器不要等待，直接开始渲染。具体方法是使用HTML中的defer和async两个属性。

事实上，defer更好一些（因为对于IE9及以下用户对于IE9及以下用户，很有可能会中断脚本）。同时，减少第三方库和脚本的使用，尤其是社交网站的分享按键和<iframe>嵌入（比如地图）。你可以使用静态的社交网站分享按键（例如SSBG的）和指向交互地图的静态链接去代替他们。

####  图片是否被正确优化？
尽可能的使用带有srcset，sizes还有<picture>元素的响应式图片。你也可以利用<picture>元素的WebP格式，用JPEG格式作为替补（参见Andreas Bovens的code snippet）或是使用内容协商（使用接受头）。Sketch原本就支持WebP，WebP图片可以直接被Photoshop的WebP plugin导出。当然也有很多其他方法。

image
响应图片断点生成器可自动处理图片

你也可以使用客户端提示，现在浏览器也可以做到。在用来生成响应图片的源文件过少时，使用响应图片断点生成器或类似Cloudinary的服务自动的优化图片。在很多案例中，单独使用sreset和sizes都带来了很大的收益。在本网站上，我们给文件添加-opt后缀——例如brotli-compression-opt.png；这样团队的每一个人就知道这些带着后最的图片是被优化过的。

####  图片的进一步优化
当你在编写登陆界面的时候，发现页面上的图片加载的特别快，这时你需要确认一下JPEG格式文件是否已经通过mozJPEG（它可以操作扫描等级从而提高渲染时间）优化和压缩，PNG格式对应Pingo，GIF需要用到Lossy GIF，SVG要使用SVGOMG。对图片不重要的部分进行模糊处理（使用高斯模糊过滤器处理他们），从而减少文件大小，最后你可能还要去彩色化使图片变成黑白，从而减少更多的容量。对于背景图片，使用Photoshop保持0到10%的质量输出是绝对可以接受的。

如果你还觉得不够，那你可以通过多重背景图片技术来提高图片的感知性能。

####  网页字体优化了吗？
你用来修饰网页字体的服务很有可能毫无用处，包括字形和额外的特性。如果你在使用开源的字体，尝试用字体库中某一个小的子集或是自己归类一个小的子集从而压缩文件大小（例如通过一些特殊的注音符号引用Latin）。WOFF2 support是个非常不错的选择，如果浏览器不支持，那你可以将WOFF和OTF作为备用。你也可以从Zach Leatherman的“Comprehensive Guide to Font-Loading Strategies”一文中选择一个合适的策略，然后使用服务器来缓存字体。如果想要快速入门，Pixel Ambacht的教程与案例会让你的字体变得尽然有序。

image
Zach Leatherman的“Comprehensive Guide to Font-Loading Strategies”提供了一打可以让字体传输变得更好的选项

如果你用的是第三方服务器主机，没办法自己在服务器上对字体进行操作，一定看看Web Font Loader。FOUT is better than FOIT中提到，在备选情况下立即渲染文本，并且异步加载字体——你也可以使用loadCSS实现这个。你可能也会避免本地OS上安装字体。

####  快速执行关键部分的CSS
为了确保浏览器尽可能快的渲染你的页面，先收集页面首次可见部分的CSS文件（也叫决定性CSS或上半版CSS）进行渲染，然后将它加入页面的部分，从而避免重复操作。因为慢启动阶段对交换包大小的限制，你关键CSS文件的大小也被限制在14KB左右。如果高于这个值，浏览器需要重复一些步骤来获取更多的样式。关键CSS是允许你这样做的。可能对每个模板都需要这个操作。如果可能，考虑一下用Fiament Group用的条件内敛方法。

通过HTTP/2，关键CSS可以单独存为CSS文件，通过服务器传输，而且可以避免HTML膨胀。服务器传输缺乏连续支持，并且存在一些超高速缓存的问题（Hooman Beheshti演示的前144页）。事实上，这样会导致网络缓冲区膨胀。因为TCP的慢启动，服务器传输在稳定的连接下会更有效率。所以你可能需要建立带有缓存的HTTP/2服务器传输机制。但请记住，新的cache-digest规则会否定手动建立的需要缓存的服务器的请求。

####  通过tree-shaking和code-splitting减少净负载
Tree-shaking是通过保留那些在项目过程中真正需要的代码从而清理你的构建过程的一种方式。你可以用Webpack 2来提出那些没用的住配置文件，用UnCSS或Helium从CSS中取出不需要的样式。同理，也可以考虑学习一下如何编写高效的CSS选择器，以及如何避免膨胀和高费的样式。

Code-splitting是另一个Webpack特性，它可以根据按需加载的块将你的代码分开。只要你在代码中定义了分离点，Webpack便会处理好相关的输出文件。它基本上能保证你初始下载的内容很小，而且在需求被添加时按需请求代码。

Rollup所展示的结果要比Browserify配置文件所显示的好得多。所以当我们想使用类似工具的时候，或许应该看看Rollupify，它将ECMAScript2015模块变成了一个更大的CommonJS模块——因为小模块没准有出乎意料的高性能成本，这源自于你对打包工具模块系统的选择。

####  提升渲染性能
使用类似CSS containment的方法对高消耗组建进行隔离，从而限制浏览器样式的范围，可以作用在为无canvas的浏览工作的布局和装饰工作中，或是用在第三方工具上。要确保页面滚动和出现动画效果时没有延迟，别忘了之前提到过的每秒60帧的原则。如果没办法做到，那就尽可能保证每秒帧数的大致范围在15到60帧。使用CSS中的will-change通知浏览器哪些元素和属性发生了变化。

也记得要衡量渲染执行中的性能（可以用DevTools）。可以参照Udacity上Paul Lewis的免费课程——浏览器渲染优化，作为入门。还有一篇Sergey Chikuyonok的文章讲了如何正确的用GPU动画。

####  预热网络连接，加快传输速度
使用页面框架，对高消耗组建延迟加载（字体，JS文件，循环播放，视频和内嵌框架）。使用资源提示来节省在dns-prefetch（指的是在后台执行DNS检索），preconnect（指要求浏览器在后台进行握手链接（DNS，TCP，TLS）），prerender（指要求浏览器在后台对特定页面进行渲染），preload（指的是提前取出暂不执行的源文件）。根据你浏览器的支持情况，尽量使用preconnect来代替dns-prefetch，而且在使用prefetch和prerender要特别小心——后者（prerender）只有在你非常确信用户下一步操作的情况下再去使用（比如购买流程中）。

HTTP/2
####  准备好使用HTTP/2
Google开始向着更安全网页的方向努力，并且将所有Chrome上的HTTP网页定义为“不安全”时，你或许应该考虑是继续使用HTTP/1.1，还是将目光转向HTTP/2环境。虽然初期投入比较大，但是使用HTTP/是大趋势，而且在熟练掌握之后，你可以使用service worker和服务器推送技术让行性能再提升一大截。

image
现在，Google计划把所有HTTP页面标记为不安全，并且将HTTP安全指示器设置为与Chrome用来拦截HTTPS的红色三角相同的图标。

使用HTTP/2的环境的缺点在于你要转移到HTTPS上，并且根据你HTTP/1.1用户的数量（主要指使用过时操作系统和过时浏览器的用户），你需要适应不同的建构过程，才能发送不同的建构。注意：不论是迁移还是新的构建过程都可能非常棘手而且耗时很多。

####  service workers是否为超高速缓存和网络提供预设机制？
没有经过优化的网络可以比用户机器的本地缓存跑得更快。如果你的网站在HTTPS上运行，你可以参考“实用主义者的service workers手册”，然后把静态资源存在service worker的缓存中，把离线预设（甚至离线页面）存在用户机器方便检索，这样比多次进行网络连接更有效。你还可以参考Jake的离线使用手册和免费的Udactiy课程“离线网络应用”。如果浏览器支持，那就再好不过了，预设就能在任何地方代替网络了。

#### 合理使用 CDN

根据你拥有的动态数据量，你可以将部分内容外包给静态站点生成工具 如 Jekyll、Hexo 生成的静态文件，接着把静态文件推到 CDN  中，最后 CDN 只是提供静态文件的静态版本。所以这样就可以避免发起对数据库的读写请求。你甚至可以选择一个基于 CDN 的静态主机平台，(这样就可以)通过给页面添加可交互组件的方式来丰富你的页面，并以此作为性能提升的标志 (JAMStack)。
请注意，CDN 也是可以托管并卸载（offload）动态内容的，所以咱们没有必要把 CDN 的服务范围限定在静态资源。（另外需要你记住的是），不管你的 CDN 是否执行内容压缩（GZip）、内容转换、HTTP/2 传输以及 ESI（一种标记语言，可以用它把网页划分为单独的可缓存的实体）等操作，我们还是需要复核上述操作的，这是因为上述操作不仅会在 CDN 的 edge 处（服务器最接近用户的地方）聚合页面中的静态以及动态内容，也还会执行其它任务。

#### 图片优化进阶别

    现在有一个至关重要着陆页，有一个特定的图片的加载速度非常关键，确保 JPEGs 是渐进式的并且使用 Adept、 mozJPEG （通过操纵扫描级来改善开始渲染时间）或者 Guetzli 压缩，谷歌新的开源编码器重点是能够感官的性能，并借鉴 Zopfli 和 WebP。唯一的 不足 是：处理的时间慢（每百万像素 CPU 一分钟）。至于 png，我们可以使用 Pingo，和 svgo，对于 SVG 的处理，我们使用 SVGO 或 SVGOMG
    每一个图像优化的文章会说明，但始终会提醒要保持矢量资源干净和紧密。确保清理未使用的资源，删除不必要的元数据，并减少图稿中的路径点数量（从而减少SVG代码）。（感谢，Jeremy！）
    到目前为止，这些优化只涵盖了基础知识。 Addy Osmani 已经发布了 一个非常详细的基本图像优化指南，深入到图像压缩和颜色管理的细节。 例如，您可以模糊图像中不必要的部分（通过对其应用高斯模糊滤镜）以减小文件大小，最终甚至可以开始移除颜色或将图像变成黑白色，以进一步缩小图像尺寸。 对于背景图像， 从Photoshop 导出的照片质量为 0 到 10％ 也是绝对可以接受的。
    那么 GIF 图片呢？我们可以使用 循环的 HTML5 视频，而不是影响渲染性能和带宽的重度 GIF 动画，而使用循环的 HTML5 视频，虽然 <video> 会使得 浏览器的性能很慢，但是与图像不同的是，浏览器不会预先加载 <video> 内容。我们也可以使用 Lossy GIF, gifsicle 或者 giflossy 添加有损压缩 GIF。
    好 消息: 希望不久以后我们可以使用 <img src=".mp4"> 来加载视频, 早期的测试表明 img 标签比同等大小的 GIF 显示速度的要快 20 多倍，解析速度要快 7 倍多。
    还不够好？那么，你也可以使用 多个背景图像技术 提高图像的感知性能。 记着，减少对比度  和模糊不必要的细节（或消除颜色）也可以减小文件的大小。 你需要放大一个小照片而不失真？考虑使用 Letsenhance.io

    Zach Leatherman 的 字体加载策略综合指南 提供了十几种更好的网页字体发送选项


#### 你是否异步加载 JavaScript？

当用户请求页面时，浏览器获取 HTML 并构造 DOM，然后获取 CSS 并构造 CSSOM，然后通过匹配 DOM 和 CSSOM 生成一个渲染树。如果有任何的 JavaScript 需要解决，浏览器将不会开始渲染页面，直到 JavaScript 解决完毕，这样就会延迟渲染。 作为开发人员，我们必须明确告诉浏览器不要等待并立即开始渲染页面。 为脚本执行此操作的方法是使用 HTML 中的 defer 和 async 属性。
事实证明，我们 应该把 async 改为 defer（因为 ie9 及以下不支持 async）。 另外，如上所述，限制第三方库和脚本的影响，特别是使用社交共享按钮和嵌入的 <iframe> 嵌入（如地图）。 大小限制 有助于防止 JavaScript 库过大：如果您不小心添加了大量依赖项，该工具将通知你并抛出错误。 你可以使用 静态社交分享按钮（如通过 SSBG ）和 静态链接 来代替交互式地图。

你对开销很大的 JS 是否使用懒加载并使用 Intersection Observer？

如果您需要延迟加载图片、视频、广告脚本、A/B 测试脚本或任何其他资源，则可以使用 Intersection Observer API，它提供了一种方法异步观察目标元素与 祖先元素或顶层文档的视口。基本上，你需要创建一个新的 IntersectionObserver 对象，它接收一个回调函数和一组选项。 然后我们添加一个目标来观察。
当目标变得可见或不可见时执行回调函数，所以当它拦截视口时，可以在元素变得可见之前开始采取一些行动。 事实上，我们可以精确地控制观察者的回调何时被调用，使用 rootMargin 和 threshold（一个数字或者一个数字数组来表示目标可见度的百分比）。Alejandro Garcia Anglada 发表了一个 简单的教程 关于如何实际实施的教程。
你甚至可以通过向你的网页添加 渐进式图片加载 来将其提升到新的水平。 与 Facebook，Pinterest 和 Medium 类似，你可以首先加载低质量或模糊的图像，然后在页面继续加载时，使用 Guy Podjarny 提出的 LQIP (Low Quality Image Placeholders) technique（低质量图像占位符）技术替换它们的清晰版本。（可以参考知乎）
如果技术提高了用户体验，观点就不一样了，但它肯定会提高第一次有意义的绘画的时间。我们甚至可以通过使用 SQIP 创建图像的低质量版本作为 SVG 占位符来实现自动化。 这些占位符可以嵌入 HTML 中，因为它们自然可以用文本压缩方法压缩。 Dean Hume 在他的文章中 描述了 如何使用 Intersection Observer 来实现这种技术。
浏览器支持程度如何呢？Decent，与 Chrome，火狐，Edge 和 Samsung Internet 已经支持了。 WebKit 目前 正在开发中。如果浏览器不支持呢？ 如果不支持Intersection Observer，我们仍然可以 延迟加载 一个 polyfill 或立即加载图像。甚至还有一个 library。
通常，我们会使用懒加载来处理所有代价较大的组件，如字体，JavaScript，轮播，视频和 iframe。 你甚至可以根据网络质量调整内容服务。网络信息 API，特别是 navigator.connection.effectiveType（Chrome 62+）使用 RTT 和下行链路值来更准确地表示连接和用户可以处理的数据。 您可以使用它来完全删除视频自动播放，背景图片或 Web 字体，以便连接速度太慢。

#### 你是否优先加载关键的 CSS？

为确保浏览器尽快开始渲染页面，通常 会收集开始渲染页面的第一个可见部分所需的所有 CSS（称为 “关键CSS” 或 “首屏 CSS”）并将其内联添加到页面的 <head> 中，从而减少往返。 由于在慢启动阶段交换包的大小有限，所以关键 CSS 的预算大约是 14 KB。
如果超出这个范围，浏览器将需要额外往返取得更多样式。  CriticalCSS 和 Critical 可以做到这一点。 你可能需要为你使用的每个模板执行此操作。 如果可能的话，考虑使用 Filament Group 使用的 条件内联方法。
使用 HTTP/2，关键 CSS 可以存储在一个单独的 CSS 文件中，并通过 服务器推送 来传递，而不会增大 HTML 的大小。 问题在于，服务器推送是很 麻烦，因为浏览器中存在许多问题和竞争条件。 它一直不被支持，并有一些缓存问题（参见 [Hooman Beheshti介绍的文章](Hooman Beheshti's presentation) 114 页内容）。事实上，这种影响可能是 负面的，会使网络缓冲区膨胀，从而阻止文档中的真实帧被传送。 而且，由于 TCP 启动缓慢，似乎服务器推送在热连接上 更加有效。
即使使用 HTTP/1，将关键 CSS 放在根目录上的单独文件中也是有 好处的，有时甚至比缓存和内联更为有效。 Chrome 请求这个页面的时候会再发送一个 HTTP 连接到根目录，从而不需要 TCP 连接来获取这个 CSS（感谢 Philip！）
需要注意的一点是：和 preload 不同的是，preload 可以触发来自任何域的预加载，而你只能从你自己的域或你所授权的域中推送资源。 一旦服务器得到来自客户端的第一个请求，就可以启动它。 服务器将资源压入缓存，并在连接终止时被删除。 但是，由于可以在多个选项卡之间重复使用 HTTP/2 连接，所以推送的资源也可以被来自其他选项卡的请求声明（感谢 Inian！）。
目前，服务器并没有一个简单的方法得知被推送的资源 是否已经存在于用户的缓存中，因此每个用户的访问都会继续推送资源。因此，您可能需要创建一个 缓存监测 HTTP/2 服务器推送机制。如果被提取，您可以尝试从缓存中获取它们，这样可以避免再次推送。
但请记住，新的 cache-digest 规范 无需手动建立这样的 “缓存感知” 的服务器，基本上在 HTTP/2 中声明的一个新的帧类型就可以表达该主机的内容。因此，它对于 CDN 也是特别有用的。
对于动态内容，当服务器需要一些时间来生成响应时，浏览器无法发出任何请求，因为它不知道页面可能引用的任何子资源。 在这种情况下，我们可以预热连接并增加 TCP 拥塞窗口大小，以便将来的请求可以更快地完成。 而且，所有内联配置对于服务器推送都是较好的选择。事实上，Inian Parameshwaran 对 HTTP/2 Push 和 HTTP Preload 进行了比较 深入的研究，内容很不错，其中包含了您可能需要的所有细节。服务器到底是推送还是不推送呢？你可以阅读一下 Colin Bendell 的  Should I Push?。
底线：正如 Sam Saccone 所说，preload 有利于将资源的开始下载时间更接近初始请求， 而服务器推送是一个完整的 RTT（或 更多，这取决于您的服务器反应时间 —— 如果你有一个服务器可以防止不必要的推送。

你使用 流响应 吗？通过流，在初始导航请求中呈现的 HTML 可以充分利用浏览器的流式 HTML 解析器。

#### 你使用流响应吗?

streams 经常被遗忘和忽略，它提供了异步读取或写入数据块的接口，在任何给定的时间内，只有一部分数据可能在内存中可用。 基本上，只要第一个数据块可用，它们就允许原始请求的页面开始处理响应，并使用针对流进行优化的解析器逐步显示内容。
我们可以从多个来源创建一个流。例如，您可以让服务器构建一个壳子来自于缓存，内容来自网络的流，而不是提供一个空的 UI 外壳并让它填充它。 正如 Jeff Posnick 指出的，如果您的 web 应用程序由 CMS 提供支持的，那么服务器渲染 HTML 是通过将部分模板拼接在一起来呈现的，该模型将直接转换为使用流式响应，而模板逻辑将从服务器复制而不是你的服务器。Jake Archibald 的 The Year of Web Streams 文章重点介绍了如何构建它。对于性能的提升是非常明显的。
流式传输整个 HTML 响应的一个重要优点是，在初始导航请求期间呈现的 HTML 可以充分利用浏览器的流式 HTML 解析器。 在页面加载之后插入到文档中的 HTML 块（与通过 JavaScript 填充的内容一样常见）无法利用此优化。
浏览器支持程度如何呢? 详情请看这里 Chrome 52+、Firefox 57、Safari 和 Edge 支持此 API 并且服务器已经支持所有的 现代浏览器.

#### 你使用 Save-Data 存储数据吗?

特别是在新兴市场工作时，你可能需要考虑优化用户选择节省数据的体验。 Save-Data 客户端提示请求头 允许我们为成本和性能受限的用户定制应用程序和有效载荷。 实际上，您可以将 高 DPI 图像的请求重写为低 DPI 图像，删除网页字体和花哨的特效，关闭视频自动播放，服务器推送，甚至更改提供标记的方式。
该头部目前仅支持 Chromium，Android 版 Chrome 或 桌面设备上的 Data Saver 扩展。最后，你还可以使用 service worker 和 Network Information API 来提供基于网络类型的低/高分辨率的图像。

#### 你是否激活了连接以加快传输？

使用 资源提示 来节约时间，如 dns-prefetch （在后台执行 DNS 查询），preconnect （告诉浏览器在后台进行连接握手（DNS, TCP, TLS）），prefetch (告诉浏览器请求一个资源) 和 preload (预先获取资源而不执行他们)。
最近，我们至少会使用 preconnect 和 dns-prefetch，我们会小心使用 prefetch 和 preload；前者只能在你非常确定用户后续需要什么资源的情况下使用（类似于采购渠道）。注意，prerender 已被弃用，不再被支持。
请注意，即使使用 preconnect 和 dns-prefetch，浏览器也会对它将并行查找或连接的主机数量进行限制，因此最好是将它们根据优先级进行排序（感谢 Philip！）。
事实上，使用资源提示可能是最简单的提高性能的方法，它确实很有效。什么时候该使用呢？Addy Osmani 已经做了解释，我们应该预加载确定将在当前页面中使用的资源。预获取可能用于未来页面的资源，例如用户尚未访问的页面所需的 Webpack 包。
Addy 的关于 Chrome 中加载优先级的文章展示了 Chrome 是如何精确地解析资源提示的，因此一旦你决定哪些资源对页面渲染比较重要，你就可以给它们赋予比较高的优先级。你可以在 Chrome DevTools 网络请求表格（或者 Safari Technology Preview）中启动“priority”列来查看你的请求的优先级。

DevTools 中的 "Priority" 列。图片来源于：Ben Schwarz，重要的请求
例如，由于字体通常是页面上的重要资源，所以最好使用 preload 请求浏览器下载字体。你也可以 动态加载 JavaScript ，从而有效的执行延迟加载。同样的，因为 <link rel="preload"> 接收一个 media 的属性，你可以基于 @media 查询规则来有选择性地优先加载资源。
需要注意的一些问题是：preload 可以 将资源的下载时间移到请求开始时，但是这些缓存在内存中的预先加载的资源是绑定在所发送请求的页面上，也就是说预先加载的请求不能被页面所共享。而且，preload 与 HTTP 缓存配合得也很好：如果缓存命中则不会发送网络请求。
因此，它对后发现的资源也非常有用，如：通过 background-image 加载的一幅 hero image，内联关键 CSS （或 JavaScript），并预先加载其他 CSS （或 JavaScript）。此外，只有当浏览器从服务器接收 HTML，并且前面的解析器找到了 preload 标签后，preload 标签才可以启动预加载。由于我们不等待浏览器解析 HTML 以启动请求，所以通过 HTTP 头进行预加载要快一些。早期提示将有助于进一步，在发送 HTML 响应标头之前启动预加载。
请注意：如果你正在使用 preload，as 必须定义否则什么都不会加载，还有，预加载字体时如果没有 crossorigin 属性将会获取两次

#### 你优化渲染性能了吗？

使用 CSS containment 隔离昂贵的组件 - 例如，限制浏览器样式、用于非画布导航的布局和绘画工作，第三方组件的范围。确保在滚动页面没有延迟，或者当一个元素进行动画时，持续地达到每秒 60 帧。如果这是不可能的，那么至少要使每秒帧数持续保持在 60 到 15 的范围。使用 CSS 的 will-change 通知浏览器哪个元素的哪个属性将要发生变化。
此外，评估运行时渲染性能（例如，使用 DevTools）。可以通过学习 Paul Lewis 免费的关于浏览器渲染优化的 Udacity 课程和 Emily Hayman 的文章优化网页动画和交互来入门。
同样，我们有 Sergey Chikuyonok 这篇文章关于如何正确使用 GPU 动画。注意：对 GPU-composited 层的更改是代价最小的，如果你能通过“不透明”和“变形”来触发合成，那么你就是在正确的道路上。

#### 你优化过渲染体验吗？

组件以何种顺序显示在页面上以及我们如何给浏览器提供资源固然重要，但是我们同样也不能低估了感知性能的角色。这一概念涉及到等待的心理学，主要是让用户在其他事情发生时保持忙碌。这就涉及到了感知管理，优先开始，提前完成和宽容管理。
这一切意味着什么？在加载资源时，我们可以尝试始终领先于客户一步，所以将很多处理放置到后台，响应会很迅速。让客户参与进来，我们可以用骨架屏幕（实例演示），而不是当没有更多优化可做时、用加载指示，添加一些动画/过渡欺骗用户体验。

### 是否启动了 OCSP stapling？

通过在你的服务上启动 OCSP stapling，你可以加速 TLS 握手。在线证书状态协议（OCSP）的提出是为了替代证书注销列表（CRL）协议。两个协议都是用于检查一个 SSL 证书是否已被撤回。但是，OCSP 协议不需要浏览器花时间下载然后在列表中搜索认证信息，因此减少了握手时间。

### 你使用（针对 HTTP 响应头压缩的）HPACK 压缩算法了吗？

如果你使用 HTTP/2，请再次检查，确保您的服务针对 HTTP 响应头部实现 HPACK 压缩以减少不必要的开销。由于 HTTP/2 服务相对较新，它们可能不完全支持该规范，HPACK 就是一个例子。可以使用 H2spec 这个伟大的（如果技术上很详细）工具来检查。HPACK作品。

### 按需加载资源
资源（特别是图片）的按需加载或者说惰性加载，可以有助于你的 Web 应用在整体上获得更好的性能。对于使用大量图片的页面来说惰性加载有着显著的三个好处：

减少向服务器发出的并发请求数量（这就使得页面的其他部分获得更快的加载时间）
减少浏览器的内存使用率（更少的图片，更少的内存）
减少服务器端的负载

### 更新：图片编码优化
    我们的一个读者指出了一个非常重要的遗漏：图片编码优化。PNGs 和 JPGs 在 Web 发布时都会使用次优的设置进行编码。通过改变编码器和它的设置，对于需要大量图片的网站来说可以获得有效的改善。流行的解决方案包括 OptiPNG 和jpegtran。

    A guide to PNG optimization 详细描述了 OptiPNG 可以如何用于优化 PNGs。

    The man page for jpegtran 对它的一些特性提供了很好的介绍。

    如果你发现这些指南相对于你的要求来说都太复杂了的话，这儿有一些在线网站可以提供优化服务。也有一些像 RIOT 一样的图形化界面，非常有助于批量操作和结果检查。


#### 2.2.DOM渲染层与GPU硬件加速



（一）CSS属性读写分离：浏览器每次对元素样式进行读操作时，都必须进行一次重新渲染（重排 + 重绘），所以我们在使用JS对元素样式进行读写操作时，最好将两者分离开，先读后写，避免出现两者交叉使用的情况。最最最客观的解决方案，就是不用JS去操作元素样式，这也是我最推荐的。

（二）通过切换class或者使用元素的style.csstext属性去批量操作元素样式。

（三）DOM元素离线更新：当对DOM进行相关操作时，例、appendChild等都可以使用Document Fragment对象进行离线操作，带元素“组装”完成后再一次插入页面，或者使用display:none 对元素隐藏，在元素“消失”后进行相关操作。

（四）将没用的元素设为不可见：visibility: hidden，这样可以减小重绘的压力，必要的时候再将元素显示。

（五）压缩DOM的深度，一个渲染层内不要有过深的子元素，少用DOM完成页面样式，多使用伪元素或者box-shadow取代。

（六）图片在渲染前指定大小：因为img元素是内联元素，所以在加载图片后会改变宽高，严重的情况会导致整个页面重排，所以最好在渲染前就指定其大小，或者让其脱离文档流。

（七）对页面中可能发生大量重排重绘的元素单独触发渲染层，使用GPU分担CPU压力。（这项策略需要慎用，得着重考量以牺牲GPU占用率为代价能否换来可期的性能优化，毕竟页面中存在太多的渲染层对于GPU而言也是一种不必要的压力，通常情况下，我们会对动画元素采取硬件加速。）

 ```
 相关知识:

    对，你没看错，页面的真实样子就是这样，是由多个DOM元素渲染层（Layers）组成的，实际上一个页面在构建完Render Tree之后，是经历了这样的流程才最终呈现在我们面前的：

     ①浏览器会先获取DOM树并依据样式将其分割成多个独立的渲染层

     ②CPU将每个层绘制进绘图中

     ③将位图作为纹理上传至GPU（显卡）绘制

     ④GPU将所有的渲染层缓存（如果下次上传的渲染层没有发生变化，GPU就不需要对其进行重绘）并复合多个渲染层最终形成我们的图像

     从上面的步骤我们可以知道，布局是由CPU处理的，而绘制则是由GPU完成的。

     其实在chrome中，也为我们提供了相关插件供我们查看页面渲染层的分布情况以及GPU的占用率：（所以说，平时我们得多去尝试尝试chrome的那些莫名其妙的插件，真的会发现好多东西都是神器）

     chrome开发者工具菜单→more tools→Layers（开启渲染层功能模块）

     chrome开发者工具菜单→more tools→rendering（开启渲染性能监测工具）

     执行上面的操作后，你会在浏览器里看到这样的效果：

     太多东西了，分模块讲吧：

     （一）最先是页面右上方的小黑窗：其实提示已经说的很清楚了，它显示的就是我们的GPU占用率，能够让我们清楚地知道页面是否发生了大量的重绘。

     （二）Layers版块：这就是用于显示我们刚提到的DOM渲染层的工具了，左侧的列表里将会列出页面里存在哪些渲染层，还有这些渲染层的详细信息。

     （三）Rendering版块：这个版块和我们的控制台在同一个地方，大家可别找不到它。前三个勾选项是我们最常使用的，让我来给大家解释一下他们的功能（充当一次免费翻译）

     ①Paint flashing：勾选之后会对页面中发生重绘的元素高亮显示

     ②Layer borders：和我们的Layer版块功能类似，它会用高亮边界突出我们页面中的各个渲染层

     ③FPS meter：就是开启我们在（一）中提到的小黑窗，用于观察我们的GPU占用率

     可能大家会问我，提到DOM渲染层这么深的概念有什么用啊，好像跟性能优化没一点关系啊？大家应该还记得我刚说到GPU会对我们的渲染层作缓存对吧，那么大家试想一下，如果我们把那些一直发生大量重排重绘的元素提取出来，单独触发一个渲染层，那样这个元素不就不会“连累”其他元素一块重绘了对吧。

     那么问题来了，什么情况下会触发渲染层呢？大家只要记住：

     Video元素、WebGL、Canvas、CSS3 3D、CSS滤镜、z-index大于某个相邻节点的元素都会触发新的Layer，其实我们最常用的方法，就是给某个元素加上下面的样式：

     transform: translateZ(0);
     backface-visibility: hidden;
     这样就可以触发渲染层啦 。

     我们把容易触发重排重绘的元素单独触发渲染层，让它与那些“静态”元素隔离，让GPU分担更多的渲染工作，我们通常把这样的措施成为硬件加速，或者是GPU加速。大家之前肯定听过这个说法，现在完全清楚它的原理了吧。

     2.3.重排与重绘
     现在到我们的重头戏了，重排和重绘。先抛出概念：

     ①重排（reflow）：渲染层内的元素布局发生修改，都会导致页面重新排列，比如窗口的尺寸发生变化、删除或添加DOM元素，修改了影响元素盒子大小的CSS属性（诸如：width、height、padding）。

     ②重绘（repaint）：绘制，即渲染上色，所有对元素的视觉表现属性的修改，都会引发重绘。

     我们习惯使用chrome devtools中的performance版块来测量页面重排重绘所占据的时间：

     ①蓝色部分：HTML解析和网络通信占用的时间

     ②黄色部分：JavaScript语句执行所占用时间

     ③紫色部分：重排占用时间

     ④绿色部分：重绘占用时间

     不论是重排还是重绘，都会阻塞浏览器。要提高网页性能，就要降低重排和重绘的频率和成本，近可能少地触发重新渲染。正如我们在2.3中提到的，重排是由CPU处理的，而重绘是由GPU处理的，CPU的处理效率远不及GPU，并且重排一定会引发重绘，而重绘不一定会引发重排。所以在性能优化工作中，我们更应当着重减少重排的发生。

     这里给大家推荐一个网站，里面详细列出了哪些CSS属性在不同的渲染引擎中是否会触发重排或重绘：

     https://csstriggers.com/ （图片来自官网）
```
[网站性能优化实战——从12.67s到1.06s的故事](https://zhuanlan.zhihu.com/p/35224473)



#### 步骤一 — HTML
浏览器从上到下读取标签，把他们分解成节点，从而创建 DOM 。



HTML 加载优化策略
样式在顶部，脚本在底部

总体思路是尽可能早的加载样式，尽可能晚的加载脚本。原因是脚本执行之前，需要 HTML 和 CSS 解析完成，因此，样式尽可能的往顶部放，当底部脚本开始执行之前，样式有足够的时间完成计算。

进一步讲讲如何优化

最小化和压缩

方法可用于所有内容，包括 HTML，CSS，JavaScript，图片和其它资源。

最小化是移除所有多余的字符，包括空格，注释，多余的分号，等等。

压缩比如 GZip，大大压缩下载文件的大小

两种方法都用的情况下，资源加载量减少了 80% 到 90%。比如： bootstrap 节省了 87% 的流量 。

无障碍

不会提升页面的下载速度，但会大大提升残障人士的满意度。给元素加上 aria 标签，图片提供 alt 文本， HTML 5 无障碍参见 。

使用诸如 WAVE 的工具鉴别哪些地方可以提高可访问性。

#### 步骤二 — CSS
当浏览器发现任何与节点相关的样式时，比如：外部，内部，或行内样式，立即停止 渲染 DOM ，并利用这些节点创建 CSSOM。这就是 CSS “ 渲染阻塞 “ 的由来。这里是不同类型样式的 优缺点 。

//外部样式<linkrel="stylesheet"href="styles.css">// 内部样式<style>
  h1 {    font-size: 18px;
  }</style>// 行内样式<buttonstyle="background-color: blue;">Click me</button>
CSSOM 节点创建与 DOM 节点创建类似，随后，两者合并如下：



CSSOM 的构建会阻塞页面的渲染，因此我们想尽早加载样式，

CSS 加载优化策略
使用 media 属性

media 属性指定加载样式的条件，比如：符合最大或最小分辨率？还是面向屏幕阅读器？

延迟加载 CSS

有些样式，比如：首屏以下的，或者不那么重要的，可以等待首屏最有价值的内容渲染完成再加载，可以使用脚本等待页面加载，然后再插入样式。

这有两个栗子： The future of loading CSS ， Defer load CSS

只加载需要的样式

使用 uncss 类似的工具，尽量移除不需要的样式。

#### 步骤三 — JavaScript
浏览器不断构建 DOM / CSSOM 节点，直到发现外部或者行内的脚本。

由于脚本可能需要访问或操作之前的 HTML 或样式，我们必须等待它们构建完成。

因此浏览器必须停止 解析 节点，完成构建 CSSOM，执行脚本，然后再继续。这就是 JavaScript 被称作“ 解析器阻塞 ”的原因。

脚本只能等到先前的 CSS 节点构建完成。



JavaScript 加载优化策略
异步加载脚本

脚本添加 async 属性，可以通知浏览器不要阻塞其余页面的加载，下载脚本处于较低的优先级。一旦下载完成，就可以执行。



async 适用于不影响 DOM 或 CSSOM 的脚本，对一些跟我们的代码无关的，不影响用户体验的外部脚本尤其适用，比如：分析统计脚本。

延迟加载脚本

defer 跟 async 非常相似，不会阻塞页面加载，但会等到 HTML 完成解析后再执行。



使用 defer 策略的 另一个好选择 ，或者也可以使用 addEventListener ，了解更多，参加 这里。

不幸的是 async 和 defer 对于行内的脚本不起作用，浏览器默认会编译执行它们。

操作之前克隆节点

多次操作 DOM 时可以尝试，首先克隆整个 DOM 节点更加高效，操作克隆后的节点，然后替换先前的节点，避免了多次重绘，降低了 CPU 和内存消耗，同时也避免了不必要的页面闪烁。

需要注意，克隆的时候并没有克隆事件监听。

Preload/Prefetch/Prerender/Preconnect

这些新属性并不是所有的浏览器都支持。了解详情可以看这里： Prefetching, preloading, prebrowsing

#### 步骤四 — 渲染树（Render Tree）
一旦所有节点已被解析，DOM 和 CSSOM 准备合并，浏览器便会构建渲染树。如果我们把节点想象成单词，那么对象模型就是句子，渲染树便是整个页面。



#### 步骤五 — 布局（Layout）
布局阶段需要确定页面上所有元素的大小和位置。



#### 步骤六 — 渲染（Paint）
最终的渲染阶段，会真正地光栅化屏幕上的像素，把页面呈现给用户。



整个过程耗时1秒或十分之一秒，我们的任务是让它更快。

如果 JavaScript 事件改变了页面的某部分，便会引起渲染树的重绘，并且迫使布局（Layout）和渲染（Paint）过程再次进行。

浏览器如何发起网络请求
当浏览器请求一个 URL，服务端会响应一些 HTML。

我们需要认识一个新术语，关键渲染路径（Critical Rendering Path (CRP)），就是浏览器渲染页面的步骤数，如下图。



#### 关键路径长度
关键渲染路径的度量标准是路径长度。最理想的关键路径长度是1。

如果页面包含一些内部样式和 JavaScript ，关键路径发生以下改变。



新增两步， 构建 CSSOM 和 执行脚本 ，因为我们的 HTML 有内部样式和脚本需要计算。由于没有外部请求，我们的关键路径长度没变。

但是注意，我们的 HTML 大小增加到了 2kb，某些地方还是受了影响。

#### 关键字节数
三个度量标准之二出现了，关键字节数，它用来衡量渲染页面需要传送多少字节数。

如果你认为不需要外部资源，就大错特错了，外部资源可以被缓存。

我们使用一个外部 CSS 文件，一个外部 JavaScript 文件，和一个外部带 async 属性的 JavaScript 文件。关键路径图如下：



浏览器请求页面，构建 DOM，发现外部资源后开始下载，CSS 和 JavaScript 有较高的优先级，其它资源次之。

styles.css 和 app.js 通过另一个关键路径获取。暂时不获取 analytics.js ，因为加了 async 属性，浏览器将用另一个线程下载它，它处于较低优先级，不会阻塞页面渲染，也不影响关键路径。

#### 关键文件
最后一个度量标准是关键文件，浏览器渲染页面需要下载的文件总量。以上例子，HTML 文件，CSS 和 JavaScript 文件算关键文件， async 的脚本不算。当然是文件越少越好。

回到关键路径长度
以上例子就是最长的渲染路径吗？我认为渲染页面时，我们仅需要下载 HTML，CSS 和 JavaScript 文件，仅通过两次服务器往返就做到了。

HTTP1 文件限制
我们浏览器的 HTTP1 协议，在同一个域名，同一次，允许下载的文件数有最大限制，范围从 2（老旧的浏览器）到 6（Edge，Chrome）。

各种浏览器请求文件的最大并发数，参见 Maximum concurrent connections to the same domain for browsers 。

通过把一些资源存放到影子域名，可以绕过这个限制，以达到最佳优化效果。

注意：不要把关键的 CSS 放到根域名之外的其他域名，有些场景下会对 DNS 查找和延迟起反作用。

#### HTTP2
如果网站使用了 HTTP2，并且用户的浏览器也兼容，则可以完全避开这个下载限制。

这里 有个 HTTP2 测试网站。

TCP 往返限制
每一次服务器往返可以传送的最大数据量是 14kb，包括所有 HTML，CSS 和脚本的网络请求。

如果我们的 HTML，或者积累的资源请求超过 14kb时，需要多做一次服务器往返。

大魔法师
我们整个 HTML 页面可以很好的压缩， GZip 可以压缩到 2kb，远低于 14kb 的限制，因此，一次服务器往返就可以搞定。



关键路径度量: 长度 1，文件数 1，字节数 2kb

浏览器发现外部资源（CSS 和 JavaScript）时，发起请求开始下载它们。首要下载的 CSS 文件是 14kb，达到了往返传输的最大限制，因此增加了一条关键路径。



关键路径度量: 长度 2，文件数 2，字节数 16kb

余下的资源低于 14kb，但是总共有 7 个资源，由于网站未启用 HTTP2，我们的 Chrome，每一次往返仅可以下载 6 个文件。



关键路径度量: 长度 3，文件数 8，字节数 28kb

下载完最终文件，并开始渲染 DOM。



关键路径度量: 长度 4，文件数 9，字节数 30kb

基于以上的信息和知识，发起每个连接时，就可以准确地预估页面的性能了。

浏览器网络优化策略
Pagespeed Insights

使用 Insights 鉴别性能问题，Chrome DevTools 也有个 audit 标签。

充分利用 Chrome 开发者工具

这篇文章 值得一读，帮你理解网络资源

在优质的环境里开发，在艰苦的环境里测试

开发时大可使用 1Tb SSD，32G 内存的 Macbook Pro ，但是性能测试时还是要到 Chrome 的 network 标签下模拟低带宽的情形，从而获取有价值的信息。

合并资源/文件

基本上，每接收到一个外部 CSS 和 JavaScript 文件，浏览器都会构建 CSSOM，执行脚本。尽管几个文件可以在一次往返中传送，但也浪费了浏览器的宝贵时间和资源，最好还是合并文件，减少不必要的加载。

首屏内容使用内部样式

内部 CSS 和 JavaScript 不需要请求外部资源，相反，外部资源又可以被缓存，并保持 DOM 轻量，两者没有非黑即白。

但是一个非常好的论点是首屏关键内容使用内部样式，可以避免请求额外的资源，节省时间做最有意义的渲染。

最小化/压缩图片

延迟加载图片

异步记载字体

是否真正需要 JavaScript / CSS?

原生 HTML 元素可以实现的行为是否用了脚本？是否有样式或者图标可以行内创建的，不需要内部/外部资源？比如： 行内 SVG 。

CDN

可以利用 CDN（内容分发网络）存储资源，它会从离用户最近，延迟最低的位置分发到用户设备，加载时间更快。

延伸阅读
Google 的优化文档

高性能浏览器网络

综述
关键渲染路径是最重要的，它使得网站优化有规律可循。需要关注3个指标：

1—关键字节数

2—关键文件数

3—关键路径长度

[[前端]浏览器前端优化](https://mp.weixin.qq.com/s?__biz=MzAxNzMwOTQ0NA==&mid=2653355020&idx=1&sn=0c8ab4fdcb3df4f7fb9edf825571666c&chksm=8035d667b7425f716c79cf8f124f34f0305b72d9b9307702680ff2783fcbb7236086951b1228#rd)



### 1.2.资源打包压缩


## 检测工具

### 1.4.网络传输性能检测工具——Page Speed
除了network版块，其实chrome还为我们准备好了一款监测网络传输性能的插件——Page Speed，咱们的文章封面，就是用的Page Speed的官方宣传图（因为我觉得这张图再合适不过了）。我们只需要通过下面步骤安装，就可以在chrome devtools里找到它了：chrome菜单→更多工具→拓展程序→chrome网上应用商店→搜索pagespeed后安转即可。

（PS：使用chrome应用商店需要翻墙，怎么翻墙我就不便多说了）

这就是Page Speed的功能界面：


我们只需要打开待测试的网页，然后点击Page Speed里的 Start analyzing按钮，它就会自动帮我们测试网络传输性能了，这是我的网站测试结果：


Page Speed最人性化的地方，便是它会对测试网站的性能瓶颈提出完整的建议，我们可以根据它的提示进行优化工作。这里我的网站已经优化到最好指标了(•́⌄•́๑)૭✧，Page Speed Score表示你的性能测试得分，100/100表示已经没有需要优化的地方。

优化完毕后再使用chorme devtools的network版块测量一下我们网页的白屏时间还有首屏时间，是不是得到了很大的提升？

### chrome开发者工具菜单→more tools→Layers（开启渲染层功能模块）

    chrome开发者工具菜单→more tools→rendering（开启渲染性能监测工具）




```
[前端性能优化指南](https://segmentfault.com/a/1190000003646305)
```





